{"ast":null,"code":"var _jsxFileName = \"/workspaces/vc_Bot/frontend/src/components/ChatBox.js\",\n  _s = $RefreshSig$();\nimport React, { useState, useRef, useEffect } from \"react\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst ChatBox = () => {\n  _s();\n  const [isListening, setIsListening] = useState(false);\n  const [transcript, setTranscript] = useState([]);\n  const mediaRecorderRef = useRef(null);\n  const socketRef = useRef(null);\n\n  // WebSocket setup\n  useEffect(() => {\n    socketRef.current = new WebSocket(\"https://fantastic-funicular-rp9vpwrw5pp25pp4-8000.app.github.dev/api/v1/chat/\");\n    socketRef.current.onopen = () => {\n      console.log(\"WebSocket connection established.\");\n    };\n    socketRef.current.onclose = () => {\n      console.log(\"WebSocket connection closed.\");\n    };\n    socketRef.current.onerror = error => {\n      console.error(\"WebSocket error:\", error);\n    };\n    socketRef.current.onmessage = event => {\n      try {\n        const response = JSON.parse(event.data);\n        if (response.user_text) {\n          setTranscript(prev => [...prev, {\n            type: \"user\",\n            text: response.user_text\n          }]);\n        }\n        if (response.llm_text) {\n          setTranscript(prev => [...prev, {\n            type: \"bot\",\n            text: response.llm_text\n          }]);\n        }\n      } catch (e) {\n        console.error(\"Error parsing WebSocket message:\", e.message);\n      }\n    };\n    return () => {\n      if (socketRef.current) {\n        socketRef.current.close();\n      }\n    };\n  }, []);\n  const handleStartListening = async () => {\n    if (socketRef.current && socketRef.current.readyState !== WebSocket.OPEN) {\n      console.error(\"Cannot start recording: WebSocket is not open.\");\n      return;\n    }\n    setIsListening(true);\n    try {\n      const stream = await navigator.mediaDevices.getUserMedia({\n        audio: true\n      });\n      mediaRecorderRef.current = new MediaRecorder(stream);\n      mediaRecorderRef.current.ondataavailable = event => {\n        if (event.data.size > 0) {\n          // Ensure WebSocket is open before sending\n          if (socketRef.current && socketRef.current.readyState === WebSocket.OPEN) {\n            socketRef.current.send(event.data);\n          } else {\n            console.error(\"WebSocket is not ready to send data.\");\n          }\n        }\n      };\n      mediaRecorderRef.current.start();\n      console.log(\"Recording started\");\n    } catch (error) {\n      console.error(\"Error accessing microphone:\", error);\n      setIsListening(false);\n    }\n  };\n  const handleStopListening = () => {\n    setIsListening(false);\n    if (mediaRecorderRef.current) {\n      mediaRecorderRef.current.stop();\n      mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());\n      mediaRecorderRef.current = null;\n    }\n    console.log(\"Recording stopped\");\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: isListening ? handleStopListening : handleStartListening,\n      children: isListening ? \"Stop Listening\" : \"Start Listening\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 91,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"transcript\",\n      children: transcript.map((entry, index) => /*#__PURE__*/_jsxDEV(\"p\", {\n        className: entry.type === \"user\" ? \"user-text\" : \"bot-text\",\n        children: entry.text\n      }, index, false, {\n        fileName: _jsxFileName,\n        lineNumber: 96,\n        columnNumber: 21\n      }, this))\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 94,\n      columnNumber: 13\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 90,\n    columnNumber: 9\n  }, this);\n};\n_s(ChatBox, \"iPZMFAny0+UuGp2belNjW0AfoDo=\");\n_c = ChatBox;\nexport default ChatBox;\nvar _c;\n$RefreshReg$(_c, \"ChatBox\");","map":{"version":3,"names":["React","useState","useRef","useEffect","jsxDEV","_jsxDEV","ChatBox","_s","isListening","setIsListening","transcript","setTranscript","mediaRecorderRef","socketRef","current","WebSocket","onopen","console","log","onclose","onerror","error","onmessage","event","response","JSON","parse","data","user_text","prev","type","text","llm_text","e","message","close","handleStartListening","readyState","OPEN","stream","navigator","mediaDevices","getUserMedia","audio","MediaRecorder","ondataavailable","size","send","start","handleStopListening","stop","getTracks","forEach","track","children","onClick","fileName","_jsxFileName","lineNumber","columnNumber","className","map","entry","index","_c","$RefreshReg$"],"sources":["/workspaces/vc_Bot/frontend/src/components/ChatBox.js"],"sourcesContent":["import React, { useState, useRef, useEffect } from \"react\";\n\nconst ChatBox = () => {\n    const [isListening, setIsListening] = useState(false);\n    const [transcript, setTranscript] = useState([]);\n    const mediaRecorderRef = useRef(null);\n    const socketRef = useRef(null);\n\n    // WebSocket setup\n    useEffect(() => {\n        socketRef.current = new WebSocket(\"https://fantastic-funicular-rp9vpwrw5pp25pp4-8000.app.github.dev/api/v1/chat/\");\n\n        socketRef.current.onopen = () => {\n            console.log(\"WebSocket connection established.\");\n        };\n\n        socketRef.current.onclose = () => {\n            console.log(\"WebSocket connection closed.\");\n        };\n\n        socketRef.current.onerror = (error) => {\n            console.error(\"WebSocket error:\", error);\n        };\n\n        socketRef.current.onmessage = (event) => {\n            try {\n                const response = JSON.parse(event.data);\n                if (response.user_text) {\n                    setTranscript((prev) => [...prev, { type: \"user\", text: response.user_text }]);\n                }\n                if (response.llm_text) {\n                    setTranscript((prev) => [...prev, { type: \"bot\", text: response.llm_text }]);\n                }\n            } catch (e) {\n                console.error(\"Error parsing WebSocket message:\", e.message);\n            }\n        };\n\n        return () => {\n            if (socketRef.current) {\n                socketRef.current.close();\n            }\n        };\n    }, []);\n\n    const handleStartListening = async () => {\n        if (socketRef.current && socketRef.current.readyState !== WebSocket.OPEN) {\n            console.error(\"Cannot start recording: WebSocket is not open.\");\n            return;\n        }\n        \n        setIsListening(true);\n    \n        try {\n            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n            mediaRecorderRef.current = new MediaRecorder(stream);\n    \n            mediaRecorderRef.current.ondataavailable = (event) => {\n                if (event.data.size > 0) {\n                    // Ensure WebSocket is open before sending\n                    if (socketRef.current && socketRef.current.readyState === WebSocket.OPEN) {\n                        socketRef.current.send(event.data);\n                    } else {\n                        console.error(\"WebSocket is not ready to send data.\");\n                    }\n                }\n            };\n    \n            mediaRecorderRef.current.start();\n            console.log(\"Recording started\");\n        } catch (error) {\n            console.error(\"Error accessing microphone:\", error);\n            setIsListening(false);\n        }\n    };\n\n    const handleStopListening = () => {\n        setIsListening(false);\n\n        if (mediaRecorderRef.current) {\n            mediaRecorderRef.current.stop();\n            mediaRecorderRef.current.stream.getTracks().forEach((track) => track.stop());\n            mediaRecorderRef.current = null;\n        }\n\n        console.log(\"Recording stopped\");\n    };\n\n    return (\n        <div>\n            <button onClick={isListening ? handleStopListening : handleStartListening}>\n                {isListening ? \"Stop Listening\" : \"Start Listening\"}\n            </button>\n            <div className=\"transcript\">\n                {transcript.map((entry, index) => (\n                    <p key={index} className={entry.type === \"user\" ? \"user-text\" : \"bot-text\"}>\n                        {entry.text}\n                    </p>\n                ))}\n            </div>\n        </div>\n    );\n};\n\nexport default ChatBox;"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,MAAM,EAAEC,SAAS,QAAQ,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAE3D,MAAMC,OAAO,GAAGA,CAAA,KAAM;EAAAC,EAAA;EAClB,MAAM,CAACC,WAAW,EAAEC,cAAc,CAAC,GAAGR,QAAQ,CAAC,KAAK,CAAC;EACrD,MAAM,CAACS,UAAU,EAAEC,aAAa,CAAC,GAAGV,QAAQ,CAAC,EAAE,CAAC;EAChD,MAAMW,gBAAgB,GAAGV,MAAM,CAAC,IAAI,CAAC;EACrC,MAAMW,SAAS,GAAGX,MAAM,CAAC,IAAI,CAAC;;EAE9B;EACAC,SAAS,CAAC,MAAM;IACZU,SAAS,CAACC,OAAO,GAAG,IAAIC,SAAS,CAAC,+EAA+E,CAAC;IAElHF,SAAS,CAACC,OAAO,CAACE,MAAM,GAAG,MAAM;MAC7BC,OAAO,CAACC,GAAG,CAAC,mCAAmC,CAAC;IACpD,CAAC;IAEDL,SAAS,CAACC,OAAO,CAACK,OAAO,GAAG,MAAM;MAC9BF,OAAO,CAACC,GAAG,CAAC,8BAA8B,CAAC;IAC/C,CAAC;IAEDL,SAAS,CAACC,OAAO,CAACM,OAAO,GAAIC,KAAK,IAAK;MACnCJ,OAAO,CAACI,KAAK,CAAC,kBAAkB,EAAEA,KAAK,CAAC;IAC5C,CAAC;IAEDR,SAAS,CAACC,OAAO,CAACQ,SAAS,GAAIC,KAAK,IAAK;MACrC,IAAI;QACA,MAAMC,QAAQ,GAAGC,IAAI,CAACC,KAAK,CAACH,KAAK,CAACI,IAAI,CAAC;QACvC,IAAIH,QAAQ,CAACI,SAAS,EAAE;UACpBjB,aAAa,CAAEkB,IAAI,IAAK,CAAC,GAAGA,IAAI,EAAE;YAAEC,IAAI,EAAE,MAAM;YAAEC,IAAI,EAAEP,QAAQ,CAACI;UAAU,CAAC,CAAC,CAAC;QAClF;QACA,IAAIJ,QAAQ,CAACQ,QAAQ,EAAE;UACnBrB,aAAa,CAAEkB,IAAI,IAAK,CAAC,GAAGA,IAAI,EAAE;YAAEC,IAAI,EAAE,KAAK;YAAEC,IAAI,EAAEP,QAAQ,CAACQ;UAAS,CAAC,CAAC,CAAC;QAChF;MACJ,CAAC,CAAC,OAAOC,CAAC,EAAE;QACRhB,OAAO,CAACI,KAAK,CAAC,kCAAkC,EAAEY,CAAC,CAACC,OAAO,CAAC;MAChE;IACJ,CAAC;IAED,OAAO,MAAM;MACT,IAAIrB,SAAS,CAACC,OAAO,EAAE;QACnBD,SAAS,CAACC,OAAO,CAACqB,KAAK,CAAC,CAAC;MAC7B;IACJ,CAAC;EACL,CAAC,EAAE,EAAE,CAAC;EAEN,MAAMC,oBAAoB,GAAG,MAAAA,CAAA,KAAY;IACrC,IAAIvB,SAAS,CAACC,OAAO,IAAID,SAAS,CAACC,OAAO,CAACuB,UAAU,KAAKtB,SAAS,CAACuB,IAAI,EAAE;MACtErB,OAAO,CAACI,KAAK,CAAC,gDAAgD,CAAC;MAC/D;IACJ;IAEAZ,cAAc,CAAC,IAAI,CAAC;IAEpB,IAAI;MACA,MAAM8B,MAAM,GAAG,MAAMC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;QAAEC,KAAK,EAAE;MAAK,CAAC,CAAC;MACzE/B,gBAAgB,CAACE,OAAO,GAAG,IAAI8B,aAAa,CAACL,MAAM,CAAC;MAEpD3B,gBAAgB,CAACE,OAAO,CAAC+B,eAAe,GAAItB,KAAK,IAAK;QAClD,IAAIA,KAAK,CAACI,IAAI,CAACmB,IAAI,GAAG,CAAC,EAAE;UACrB;UACA,IAAIjC,SAAS,CAACC,OAAO,IAAID,SAAS,CAACC,OAAO,CAACuB,UAAU,KAAKtB,SAAS,CAACuB,IAAI,EAAE;YACtEzB,SAAS,CAACC,OAAO,CAACiC,IAAI,CAACxB,KAAK,CAACI,IAAI,CAAC;UACtC,CAAC,MAAM;YACHV,OAAO,CAACI,KAAK,CAAC,sCAAsC,CAAC;UACzD;QACJ;MACJ,CAAC;MAEDT,gBAAgB,CAACE,OAAO,CAACkC,KAAK,CAAC,CAAC;MAChC/B,OAAO,CAACC,GAAG,CAAC,mBAAmB,CAAC;IACpC,CAAC,CAAC,OAAOG,KAAK,EAAE;MACZJ,OAAO,CAACI,KAAK,CAAC,6BAA6B,EAAEA,KAAK,CAAC;MACnDZ,cAAc,CAAC,KAAK,CAAC;IACzB;EACJ,CAAC;EAED,MAAMwC,mBAAmB,GAAGA,CAAA,KAAM;IAC9BxC,cAAc,CAAC,KAAK,CAAC;IAErB,IAAIG,gBAAgB,CAACE,OAAO,EAAE;MAC1BF,gBAAgB,CAACE,OAAO,CAACoC,IAAI,CAAC,CAAC;MAC/BtC,gBAAgB,CAACE,OAAO,CAACyB,MAAM,CAACY,SAAS,CAAC,CAAC,CAACC,OAAO,CAAEC,KAAK,IAAKA,KAAK,CAACH,IAAI,CAAC,CAAC,CAAC;MAC5EtC,gBAAgB,CAACE,OAAO,GAAG,IAAI;IACnC;IAEAG,OAAO,CAACC,GAAG,CAAC,mBAAmB,CAAC;EACpC,CAAC;EAED,oBACIb,OAAA;IAAAiD,QAAA,gBACIjD,OAAA;MAAQkD,OAAO,EAAE/C,WAAW,GAAGyC,mBAAmB,GAAGb,oBAAqB;MAAAkB,QAAA,EACrE9C,WAAW,GAAG,gBAAgB,GAAG;IAAiB;MAAAgD,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC/C,CAAC,eACTtD,OAAA;MAAKuD,SAAS,EAAC,YAAY;MAAAN,QAAA,EACtB5C,UAAU,CAACmD,GAAG,CAAC,CAACC,KAAK,EAAEC,KAAK,kBACzB1D,OAAA;QAAeuD,SAAS,EAAEE,KAAK,CAAChC,IAAI,KAAK,MAAM,GAAG,WAAW,GAAG,UAAW;QAAAwB,QAAA,EACtEQ,KAAK,CAAC/B;MAAI,GADPgC,KAAK;QAAAP,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAEV,CACN;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACD,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACL,CAAC;AAEd,CAAC;AAACpD,EAAA,CApGID,OAAO;AAAA0D,EAAA,GAAP1D,OAAO;AAsGb,eAAeA,OAAO;AAAC,IAAA0D,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}